{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N=500):\n",
    "    N = N # Number of Samples\n",
    "    D = 2 #Dimensions\n",
    "    # Random data points\n",
    "    half = N//2\n",
    "    X = np.random.randn(N, D)\n",
    "\n",
    "    # Dividing above samples into 2 different gaussian blobs\n",
    "    X[ :half, : ] = X[ :half, : ] - 2*np.ones((half, D))\n",
    "    X[half:, : ] = X[half:, : ] + 2*np.ones((half, D))\n",
    "\n",
    "    # Creating targets for above 2 blobs\n",
    "    Y = np.array([0]*half + [1]*half)\n",
    "\n",
    "    bias_term = np.ones((N, 1))\n",
    "\n",
    "    # Adding bias term to our data\n",
    "    Xbias = np.concatenate((X, bias_term), axis=1)\n",
    "\n",
    "    return Xbias, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "\n",
    "    def fit(self, X, Y, smoothing=10e-1):\n",
    "        self.gaussians = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        labels = set(Y)\n",
    "        for c in labels:\n",
    "            current_x = X[Y==c]\n",
    "            self.gaussians[c] = {\n",
    "                'mean': current_x.mean(axis=0),\n",
    "                'variance': current_x.var(axis=0) + smoothing,\n",
    "            }\n",
    "\n",
    "            self.priors[c] = float(len(Y[Y==c])) / len(Y)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean( Y == predictions )\n",
    "\n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        k = len(self.gaussians)\n",
    "        p = np.zeros((N, k))\n",
    "        for c, g in self.gaussians.items():\n",
    "            mean, var = g['mean'], g['variance']\n",
    "            p[ :, c] = multivariate_normal.logpdf(X, mean=mean, cov=var) + np.log(self.priors[c])\n",
    "        \n",
    "        return np.argmax(p, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set 0.9979\n",
      "Accuracy on test set 0.997\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayes()\n",
    "\n",
    "X_train, Y_train = get_data(10000) \n",
    "\n",
    "X_test, Y_test = get_data(2000)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Accuracy on training set {classifier.score(X_train, Y_train)}')\n",
    "\n",
    "preds = classifier.predict(X_test)\n",
    "\n",
    "print(f'Accuracy on test set {classifier.score(X_test, Y_test)}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c0b1b5056800b9bcfddddd535b7a73e2e1c0c01aa1255f77f1ff629d8e076c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
